{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exwleYwQLsAz",
    "outputId": "316df4c3-d132-40b2-f249-ed9c2f920a04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/guest/thdaryan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score as meteor\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /scratch2/thdaryan/data/fine_tuned/refCOCO/test/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iL_6vmarNGYw"
   },
   "outputs": [],
   "source": [
    "labels_folder_path = '/scratch2/thdaryan/data/fine_tuned/refCOCO/test/labels'\n",
    "result_folder_path = 'result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygpyEQbANQoX",
    "outputId": "41dbc4c8-9e0d-431a-b739-41d807801e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['guy petting elephant', 'foremost person', 'green shirt']\n",
      "[['guy', 'petting', 'elephant'], ['foremost', 'person'], ['green', 'shirt']]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(labels_folder_path, 'lab_0.json')) as f:\n",
    "    sample_label = json.load(f)\n",
    "print(sample_label['ref_sents'])\n",
    "\n",
    "ref = sample_label['ref_sents']\n",
    "exp = [word_tokenize(r.lower()) for r in ref]\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXzbZeQJNRIC",
    "outputId": "1e08913f-cf44-4c27-b0fe-4661c300e91f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36787944117144233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "print(sentence_bleu(exp, ['foremost'], weights=(1,0,0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKLQpL3qOEVB",
    "outputId": "864fdaa7-dd3d-4e35-a698-adc7f58eafe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^man is sitting on the ground$', '-5.629921482260508']\n",
      "man is sitting on the ground\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(result_folder_path, 'result_pragmatic_caption_0_1000.json')) as f:\n",
    "    result_0_1000 = json.load(f)\n",
    "print(result_0_1000['0'])\n",
    "print(result_0_1000['0'][0][1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7q4cKP-QOTvP",
    "outputId": "1d2bb72b-0284-4ab0-dc06-1fa7b59dfa5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/scratch2/hle/py3_env/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:00<00:01,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:00<00:01,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:01<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:01<00:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "bleu_scores = []\n",
    "for file in tqdm(range(0, 5000, 1000)):\n",
    "    print(file, file+1000)\n",
    "    with open(os.path.join(result_folder_path, f'result_pragmatic_caption_{file}_{file+1000}.json')) as f:\n",
    "        list_result = json.load(f)\n",
    "    for idx in list_result:\n",
    "        result = list_result[idx]\n",
    "        if (result[0]=='ERROR'):\n",
    "#             print(idx, result)\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(labels_folder_path, f'lab_{idx}.json')) as f:\n",
    "            sample_label = json.load(f)\n",
    "\n",
    "        ref = sample_label['ref_sents']\n",
    "        ref = [word_tokenize(r.lower()) for r in ref]\n",
    "\n",
    "        generated_exp = result[0][1:-1]\n",
    "        score = sentence_bleu(ref, word_tokenize(generated_exp), weights=(1,0,0,0))\n",
    "\n",
    "#         print(score, ref,  word_tokenize(generated_exp))\n",
    "        bleu_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ejsmcb1UQIaf",
    "outputId": "27221a7a-325d-4192-a660-79836bee5c8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4984"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc8kknDnSMpI",
    "outputId": "20c7a8ba-b9f2-4fca-de37-887f2d3e08f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168943800017137"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(bleu_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STUWyaTRSo__"
   },
   "source": [
    "## Calculate Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:00<00:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:01<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:02<00:01,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:02<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "rouge1_scores = []\n",
    "rougeL_scores = []\n",
    "for file in tqdm(range(0, 5000, 1000)):\n",
    "    print(file, file+1000)\n",
    "    with open(os.path.join(result_folder_path, f'result_pragmatic_caption_{file}_{file+1000}.json')) as f:\n",
    "        list_result = json.load(f)\n",
    "    for idx in list_result:\n",
    "        result = list_result[idx]\n",
    "        if (result[0]=='ERROR'):\n",
    "#             print(idx, result)\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(labels_folder_path, f'lab_{idx}.json')) as f:\n",
    "            sample_label = json.load(f)\n",
    "\n",
    "        ref = sample_label['ref_sents']\n",
    "        generated_exp = result[0][1:-1]\n",
    "        rouge1_scores.append(np.average([scorer.score(target, generated_exp)['rouge1'].recall for target in ref]))\n",
    "        rougeL_scores.append(np.average([scorer.score(target, generated_exp)['rougeL'].recall for target in ref]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14807628272710655 0.17988326157351756\n"
     ]
    }
   ],
   "source": [
    "print(np.average(rouge1_scores), np.std(rouge1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14305185991986696 0.17403894462041697\n"
     ]
    }
   ],
   "source": [
    "print(np.average(rougeL_scores), np.std(rougeL_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Meteor Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:02<00:08,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:02<00:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:03<00:02,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:04<00:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "meteor_scores = []\n",
    "for file in tqdm(range(0, 5000, 1000)):\n",
    "    print(file, file+1000)\n",
    "    with open(os.path.join(result_folder_path, f'result_pragmatic_caption_{file}_{file+1000}.json')) as f:\n",
    "        list_result = json.load(f)\n",
    "    for idx in list_result:\n",
    "        result = list_result[idx]\n",
    "        if (result[0]=='ERROR'):\n",
    "#             print(idx, result)\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(labels_folder_path, f'lab_{idx}.json')) as f:\n",
    "            sample_label = json.load(f)\n",
    "\n",
    "        ref = sample_label['ref_sents']\n",
    "        ref = [r.lower() for r in ref]\n",
    "\n",
    "        generated_exp = result[0][1:-1]\n",
    "        score = meteor(ref, generated_exp)\n",
    "\n",
    "        meteor_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13534073040601782 0.15401653259086828\n"
     ]
    }
   ],
   "source": [
    "print(np.average(meteor_scores), np.std(meteor_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Calculate_score_reuben.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
